{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# F1 Race Position Prediction Model\n",
    "\n",
    "## Project Overview\n",
    "In this notebook, we'll build a machine learning model to predict final race positions in Formula 1. We'll use historical race data and various features like qualifying position, driver performance, and circuit characteristics.\n",
    "\n",
    "## What You'll Learn:\n",
    "1. **Data Collection**: How to fetch F1 data using APIs\n",
    "2. **Exploratory Data Analysis (EDA)**: Understanding patterns in the data\n",
    "3. **Feature Engineering**: Creating meaningful features for predictions\n",
    "4. **Model Training**: Using Random Forest and XGBoost\n",
    "5. **Model Evaluation**: Measuring how well our model performs\n",
    "6. **Making Predictions**: Using the model for future races"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imports",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries\n",
    "\n",
    "Let's import all the libraries we'll need. Each library has a specific purpose:\n",
    "- **pandas**: Working with data in table format (DataFrames)\n",
    "- **numpy**: Numerical operations and arrays\n",
    "- **matplotlib & seaborn**: Creating visualizations\n",
    "- **fastf1**: Fetching F1 data\n",
    "- **scikit-learn**: Machine learning algorithms and tools\n",
    "- **xgboost**: Advanced gradient boosting algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "import_cell",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Data manipulation\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Visualization\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# F1 data\n",
    "import fastf1\n",
    "from fastf1 import plotting\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import xgboost as xgb\n",
    "\n",
    "# Utilities\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Enable FastF1 cache to speed up data loading\n",
    "fastf1.Cache.enable_cache(\"cache\")\n",
    "print(\"hello\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "schedule = fastf1.get_event_schedule(2025)\n",
    "print(schedule)\n",
    "race = fastf1.get_session(2024, 'Las Vegas Grand Prix', 'R')\n",
    "#race.load()  # This fetches the data\n",
    "print(race)\n",
    "\n",
    "def get_qualifying_results(year, event_name):\n",
    "\n",
    "    try:\n",
    "        # Load qualifying session\n",
    "        quali = fastf1.get_session(year, event_name, 'Q')\n",
    "        quali.load()\n",
    "        \n",
    "        # Get qualifying results\n",
    "        results = quali.results\n",
    "        \n",
    "        # Select relevant columns\n",
    "        quali_data = results[[\n",
    "            'Position', 'Abbreviation', 'TeamName', 'Q1', 'Q2', 'Q3'\n",
    "        ]].copy()\n",
    "        \n",
    "        # Sort by position\n",
    "        quali_data = quali_data.sort_values('Position')\n",
    "        \n",
    "        return quali_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for {year} {event_name}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Fetch Las Vegas GP qualifying results\n",
    "print(\"=\"*80)\n",
    "print(\"LAS VEGAS GRAND PRIX - QUALIFYING RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 2023 Las Vegas GP\n",
    "print(\"\\nüèÅ 2023 LAS VEGAS GRAND PRIX - QUALIFYING\\n\")\n",
    "quali_2023 = get_qualifying_results(2023, 'Las Vegas Grand Prix')\n",
    "if quali_2023 is not None:\n",
    "    print(quali_2023.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# 2024 Las Vegas GP\n",
    "print(\"\\nüèÅ 2024 LAS VEGAS GRAND PRIX - QUALIFYING\\n\")\n",
    "quali_2024 = get_qualifying_results(2024, 'Las Vegas Grand Prix')\n",
    "if quali_2024 is not None:\n",
    "    print(quali_2024.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# 2025 Las Vegas GP\n",
    "print(\"\\nüèÅ 2025 LAS VEGAS GRAND PRIX - QUALIFYING\\n\")\n",
    "quali_2025 = get_qualifying_results(2025, 'Las Vegas Grand Prix')\n",
    "if quali_2025 is not None:\n",
    "    print(quali_2025.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "def get_race_results(year, event_name):\n",
    "    try:\n",
    "        # Load qualifying session\n",
    "        race = fastf1.get_session(year, event_name, 'R')\n",
    "        race.load()\n",
    "        \n",
    "        # Get qualifying results\n",
    "        results = race.results.copy()\n",
    "        \n",
    "        # Select relevant columns\n",
    "        race_data = results[[\n",
    "            'ClassifiedPosition', 'Abbreviation', 'TeamName', 'Time', 'GridPosition'\n",
    "        ]].copy()\n",
    "        \n",
    "        # Sort by position\n",
    "        race_data = race_data.sort_values('ClassifiedPosition')\n",
    "        \n",
    "        return race_data\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data for {year} {event_name}: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Fetch Las Vegas GP race results\n",
    "print(\"=\"*80)\n",
    "print(\"LAS VEGAS GRAND PRIX - RACE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# 2023 Las Vegas GP\n",
    "print(\"\\nüèÅ 2023 LAS VEGAS GRAND PRIX - RACE\\n\")\n",
    "race_2023 = get_race_results(2023, 'Las Vegas Grand Prix')\n",
    "if race_2023 is not None:\n",
    "    print(race_2023.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# 2024 Las Vegas GP\n",
    "print(\"\\nüèÅ 2024 LAS VEGAS GRAND PRIX - RACE\\n\")\n",
    "race_2024 = get_race_results(2024, 'Las Vegas Grand Prix')\n",
    "if race_2024 is not None:\n",
    "    print(race_2024.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599072e",
   "metadata": {},
   "outputs": [],
   "source": "import sys\nprint(\"Python executable:\", sys.executable)\nprint(\"Python version:\", sys.version)\nprint(\"\\nInstalled packages location:\")\nprint(sys.path[:3])"
  },
  {
   "cell_type": "markdown",
   "id": "data_collection_md",
   "metadata": {},
   "source": [
    "## Step 2: Data Collection\n",
    "\n",
    "We'll use the FastF1 library to fetch historical race data. FastF1 provides:\n",
    "- Race results (finishing positions)\n",
    "- Qualifying results (starting positions)\n",
    "- Lap times and telemetry data\n",
    "- Driver and team information\n",
    "\n",
    "**Key Concept**: In machine learning, we need historical data to train our model. The more quality data we have, the better our predictions.\n",
    "\n",
    "Let's start by fetching data from recent F1 seasons (2022-2023)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fetch_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def fetch_season_data(year):\n",
    "    print(f\"\\nFetching data for {year} season...\")\n",
    "    season_data = []\n",
    "    \n",
    "    # Get the schedule for the year\n",
    "    schedule = fastf1.get_event_schedule(year)\n",
    "    \n",
    "    # Iterate through each race\n",
    "    for idx, event in tqdm(schedule.iterrows(), total=len(schedule), desc=f\"{year} Races\"):\n",
    "        # Skip testing and sprint events, only get main races\n",
    "        if event['EventFormat'] != 'conventional':\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            # Load the race session\n",
    "            race = fastf1.get_session(year, event['EventName'], 'R')\n",
    "            race.load()\n",
    "            \n",
    "            # Get race results\n",
    "            results = race.results\n",
    "            \n",
    "            # Add metadata\n",
    "            results['Year'] = year\n",
    "            results['RaceName'] = event['EventName']\n",
    "            results['Country'] = event['Country']\n",
    "            results['RoundNumber'] = event['RoundNumber']\n",
    "            \n",
    "            # Try to get qualifying data\n",
    "            try:\n",
    "                quali = fastf1.get_session(year, event['EventName'], 'Q')\n",
    "                quali.load()\n",
    "                quali_results = quali.results[['Abbreviation', 'Position']]\n",
    "                quali_results = quali_results.rename(columns={'Position': 'QualiPosition'})\n",
    "                \n",
    "                # Merge qualifying position\n",
    "                results = results.merge(quali_results, on='Abbreviation', how='left')\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load qualifying for {event['EventName']}: {e}\")\n",
    "                results['QualiPosition'] = None\n",
    "            \n",
    "            season_data.append(results)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error loading {event['EventName']}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # Combine all races into one DataFrame\n",
    "    if season_data:\n",
    "        return pd.concat(season_data, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Fetch data for 2022 and 2023 seasons\n",
    "# You can add more years if you want more training data\n",
    "df_2022 = fetch_season_data(2022)\n",
    "df_2023 = fetch_season_data(2023)\n",
    "\n",
    "print(df_2023)\n",
    "\n",
    "# Combine all data\n",
    "#df_raw = pd.concat([df_2022, df_2023], ignore_index=True)\n",
    "\n",
    "#print(f\"\\n{'='*50}\")\n",
    "#print(f\"Total races fetched: {df_raw['RaceName'].nunique()}\")\n",
    "#print(f\"Total records: {len(df_raw)}\")\n",
    "#print(f\"{'='*50}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "first_look_md",
   "metadata": {},
   "source": [
    "## Step 3: First Look at the Data\n",
    "\n",
    "Before building any model, we need to understand our data:\n",
    "- What columns do we have?\n",
    "- Are there any missing values?\n",
    "- What do the values look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explore_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\n",
    "# Display first few rows\n",
    "print(\"First 5 rows of data:\")\n",
    "\n",
    "print(df_raw.head())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Data Info:\")\n",
    "print(df_raw.info())\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Key columns:\")\n",
    "print(df_raw[['DriverNumber', 'Abbreviation', 'TeamName', 'Position', 'QualiPosition', 'GridPosition']].head(10))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda_md",
   "metadata": {},
   "source": [
    "## Step 4: Exploratory Data Analysis (EDA)\n",
    "\n",
    "**What is EDA?**\n",
    "EDA is the process of analyzing data to discover patterns, spot anomalies, and test assumptions. This helps us:\n",
    "1. Understand which features are important\n",
    "2. Identify relationships between variables\n",
    "3. Detect outliers or missing data\n",
    "\n",
    "Let's visualize some key relationships!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Qualifying Position vs Race Position\n",
    "# This shows how starting position affects finishing position\n",
    "ax1 = axes[0, 0]\n",
    "valid_data = df_raw.dropna(subset=['QualiPosition', 'Position'])\n",
    "ax1.scatter(valid_data['QualiPosition'], valid_data['Position'], alpha=0.5)\n",
    "ax1.plot([0, 20], [0, 20], 'r--', label='Perfect correlation')\n",
    "ax1.set_xlabel('Qualifying Position', fontsize=12)\n",
    "ax1.set_ylabel('Final Race Position', fontsize=12)\n",
    "ax1.set_title('Qualifying Position vs Final Position\\n(Shows importance of qualifying)', fontsize=14)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Distribution of finishing positions\n",
    "ax2 = axes[0, 1]\n",
    "df_raw['Position'].value_counts().sort_index().plot(kind='bar', ax=ax2, color='skyblue')\n",
    "ax2.set_xlabel('Final Position', fontsize=12)\n",
    "ax2.set_ylabel('Frequency', fontsize=12)\n",
    "ax2.set_title('Distribution of Final Positions', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Wins by team\n",
    "ax3 = axes[1, 0]\n",
    "winners = df_raw[df_raw['Position'] == 1]\n",
    "team_wins = winners['TeamName'].value_counts().head(10)\n",
    "team_wins.plot(kind='barh', ax=ax3, color='coral')\n",
    "ax3.set_xlabel('Number of Wins', fontsize=12)\n",
    "ax3.set_title('Race Wins by Team (Top 10)', fontsize=14)\n",
    "ax3.grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# 4. Correlation heatmap for numerical features\n",
    "ax4 = axes[1, 1]\n",
    "numerical_cols = ['Position', 'QualiPosition', 'GridPosition', 'Points']\n",
    "corr_data = df_raw[numerical_cols].dropna()\n",
    "correlation = corr_data.corr()\n",
    "sns.heatmap(correlation, annot=True, fmt='.2f', cmap='coolwarm', ax=ax4, center=0)\n",
    "ax4.set_title('Correlation Between Features', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./data/eda_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey Insights from EDA:\")\n",
    "print(\"1. Qualifying position strongly influences final position\")\n",
    "print(\"2. Some teams dominate race wins\")\n",
    "print(\"3. Grid position and qualifying position are highly correlated\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_eng_md",
   "metadata": {},
   "source": [
    "## Step 5: Feature Engineering\n",
    "\n",
    "**What is Feature Engineering?**\n",
    "It's the process of creating new features (variables) from existing data to help the model make better predictions.\n",
    "\n",
    "**Features we'll create:**\n",
    "1. **Driver Performance**: Average finishing position in previous races\n",
    "2. **Team Performance**: Team's average position\n",
    "3. **Starting Position Quality**: Qualifying performance\n",
    "4. **Driver Experience**: Number of races completed\n",
    "5. **Recent Form**: Performance in last 3 races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_engineering",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Make a copy of the data\n",
    "df = df_raw.copy()\n",
    "\n",
    "# Clean data: remove rows without essential information\n",
    "df = df.dropna(subset=['Position', 'QualiPosition'])\n",
    "\n",
    "# Convert position to integer\n",
    "df['Position'] = df['Position'].astype(int)\n",
    "df['QualiPosition'] = df['QualiPosition'].astype(int)\n",
    "\n",
    "# Sort by year and round to ensure chronological order\n",
    "df = df.sort_values(['Year', 'RoundNumber']).reset_index(drop=True)\n",
    "\n",
    "print(\"Creating features...\\n\")\n",
    "\n",
    "# Feature 1: Driver's average position in previous races\n",
    "df['DriverAvgPosition'] = df.groupby('Abbreviation')['Position'].transform(\n",
    "    lambda x: x.expanding().mean().shift(1)\n",
    ")\n",
    "\n",
    "# Feature 2: Team's average position\n",
    "df['TeamAvgPosition'] = df.groupby('TeamName')['Position'].transform(\n",
    "    lambda x: x.expanding().mean().shift(1)\n",
    ")\n",
    "\n",
    "# Feature 3: Driver's race count (experience)\n",
    "df['DriverRaceCount'] = df.groupby('Abbreviation').cumcount()\n",
    "\n",
    "# Feature 4: Recent form - average of last 3 races\n",
    "df['RecentForm'] = df.groupby('Abbreviation')['Position'].transform(\n",
    "    lambda x: x.rolling(window=3, min_periods=1).mean().shift(1)\n",
    ")\n",
    "\n",
    "# Feature 5: Qualifying improvement - difference from average quali\n",
    "df['QualiImprovement'] = df.groupby('Abbreviation')['QualiPosition'].transform(\n",
    "    lambda x: x.expanding().mean().shift(1)\n",
    ") - df['QualiPosition']\n",
    "\n",
    "# Feature 6: Grid penalty (difference between qualifying and grid position)\n",
    "df['GridPenalty'] = df['GridPosition'] - df['QualiPosition']\n",
    "\n",
    "# Encode categorical variables\n",
    "le_driver = LabelEncoder()\n",
    "le_team = LabelEncoder()\n",
    "le_circuit = LabelEncoder()\n",
    "\n",
    "df['Driver_Encoded'] = le_driver.fit_transform(df['Abbreviation'])\n",
    "df['Team_Encoded'] = le_team.fit_transform(df['TeamName'])\n",
    "df['Circuit_Encoded'] = le_circuit.fit_transform(df['RaceName'])\n",
    "\n",
    "print(\"Features created successfully!\\n\")\n",
    "print(\"New features:\")\n",
    "print(df[['Abbreviation', 'Position', 'QualiPosition', 'DriverAvgPosition', \n",
    "          'TeamAvgPosition', 'DriverRaceCount', 'RecentForm']].head(15))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepare_data_md",
   "metadata": {},
   "source": [
    "## Step 6: Prepare Data for Machine Learning\n",
    "\n",
    "**Key Concepts:**\n",
    "\n",
    "1. **Features (X)**: The input variables our model uses to make predictions\n",
    "2. **Target (y)**: What we're trying to predict (final race position)\n",
    "3. **Train/Test Split**: We split data into:\n",
    "   - **Training set**: Used to teach the model\n",
    "   - **Test set**: Used to evaluate how well the model performs on unseen data\n",
    "\n",
    "**Why split the data?**\n",
    "If we test on the same data we trained on, we can't tell if the model actually learned patterns or just memorized the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepare_ml_data",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Remove rows with missing values in our features\n",
    "df_clean = df.dropna(subset=[\n",
    "    'QualiPosition', 'DriverAvgPosition', 'TeamAvgPosition', \n",
    "    'DriverRaceCount', 'RecentForm', 'GridPenalty'\n",
    "])\n",
    "\n",
    "# Define features (X) - what the model will use to make predictions\n",
    "feature_columns = [\n",
    "    'QualiPosition',        # Starting position from qualifying\n",
    "    'DriverAvgPosition',    # Driver's historical average\n",
    "    'TeamAvgPosition',      # Team's performance\n",
    "    'DriverRaceCount',      # Driver experience\n",
    "    'RecentForm',           # Recent performance\n",
    "    'GridPenalty',          # Any grid penalties\n",
    "    'Driver_Encoded',       # Driver identity (encoded)\n",
    "    'Team_Encoded',         # Team identity (encoded)\n",
    "    'Circuit_Encoded'       # Circuit characteristics (encoded)\n",
    "]\n",
    "\n",
    "X = df_clean[feature_columns]\n",
    "y = df_clean['Position']  # Target: final race position\n",
    "\n",
    "# Split data: 80% training, 20% testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Data Preparation Complete!\\n\")\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Test set size: {len(X_test)} samples\")\n",
    "print(f\"\\nFeatures being used: {len(feature_columns)}\")\n",
    "print(f\"Feature names: {feature_columns}\")\n",
    "print(f\"\\nTarget variable range: {y.min()} to {y.max()}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model_training_md",
   "metadata": {},
   "source": [
    "## Step 7: Train Machine Learning Models\n",
    "\n",
    "We'll train two types of models and compare them:\n",
    "\n",
    "### 1. Random Forest Regressor\n",
    "**What is it?**\n",
    "- Creates many decision trees and averages their predictions\n",
    "- Each tree learns different patterns from the data\n",
    "- Very robust and handles complex relationships well\n",
    "\n",
    "**Why use it?**\n",
    "- Good for beginners - easy to understand\n",
    "- Handles non-linear relationships\n",
    "- Less prone to overfitting\n",
    "\n",
    "### 2. XGBoost (Extreme Gradient Boosting)\n",
    "**What is it?**\n",
    "- Builds trees sequentially, each correcting errors of previous ones\n",
    "- One of the most powerful ML algorithms\n",
    "- Often wins Kaggle competitions\n",
    "\n",
    "**Why use it?**\n",
    "- Usually gives better accuracy\n",
    "- Fast training and prediction\n",
    "- Can handle missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train_models",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "print(\"Training Machine Learning Models...\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Model 1: Random Forest Regressor\n",
    "print(\"\\n1. Training Random Forest Model...\")\n",
    "rf_model = RandomForestRegressor(\n",
    "    n_estimators=200,      # Number of trees in the forest\n",
    "    max_depth=15,          # Maximum depth of each tree\n",
    "    min_samples_split=5,   # Minimum samples to split a node\n",
    "    random_state=42,       # For reproducibility\n",
    "    n_jobs=-1              # Use all CPU cores\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "print(\"   Random Forest trained!\")\n",
    "\n",
    "# Make predictions\n",
    "rf_predictions = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "rf_mae = mean_absolute_error(y_test, rf_predictions)\n",
    "print(f\"   Mean Absolute Error: {rf_mae:.2f} positions\")\n",
    "print(f\"   This means on average, predictions are off by {rf_mae:.2f} positions\")\n",
    "\n",
    "# Model 2: XGBoost\n",
    "print(\"\\n2. Training XGBoost Model...\")\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "print(\"   XGBoost trained!\")\n",
    "\n",
    "# Make predictions\n",
    "xgb_predictions = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "xgb_mae = mean_absolute_error(y_test, xgb_predictions)\n",
    "print(f\"   Mean Absolute Error: {xgb_mae:.2f} positions\")\n",
    "print(f\"   This means on average, predictions are off by {xgb_mae:.2f} positions\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Model Comparison:\")\n",
    "print(f\"Random Forest MAE: {rf_mae:.2f}\")\n",
    "print(f\"XGBoost MAE: {xgb_mae:.2f}\")\n",
    "print(f\"\\nBest Model: {'XGBoost' if xgb_mae < rf_mae else 'Random Forest'}\")\n",
    "print(\"=\"*60)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feature_importance_md",
   "metadata": {},
   "source": [
    "## Step 8: Feature Importance Analysis\n",
    "\n",
    "**What is Feature Importance?**\n",
    "It tells us which features (variables) have the most influence on predictions. This helps us:\n",
    "1. Understand what drives race outcomes\n",
    "2. Simplify the model by removing unimportant features\n",
    "3. Gain insights into F1 racing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature_importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Get feature importances from both models\n",
    "rf_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'Feature': feature_columns,\n",
    "    'Importance': xgb_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Random Forest importance\n",
    "axes[0].barh(rf_importance['Feature'], rf_importance['Importance'], color='steelblue')\n",
    "axes[0].set_xlabel('Importance Score', fontsize=12)\n",
    "axes[0].set_title('Random Forest - Feature Importance', fontsize=14, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# XGBoost importance\n",
    "axes[1].barh(xgb_importance['Feature'], xgb_importance['Importance'], color='coral')\n",
    "axes[1].set_xlabel('Importance Score', fontsize=12)\n",
    "axes[1].set_title('XGBoost - Feature Importance', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./data/feature_importance.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nTop 5 Most Important Features (XGBoost):\")\n",
    "print(xgb_importance.head())\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "evaluation_md",
   "metadata": {},
   "source": [
    "## Step 9: Model Evaluation and Visualization\n",
    "\n",
    "Let's visualize how well our model performs by comparing:\n",
    "- Actual positions vs Predicted positions\n",
    "- Distribution of prediction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluation_viz",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Create evaluation visualizations\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# Choose the better model\n",
    "best_predictions = xgb_predictions if xgb_mae < rf_mae else rf_predictions\n",
    "best_model_name = 'XGBoost' if xgb_mae < rf_mae else 'Random Forest'\n",
    "\n",
    "# 1. Actual vs Predicted scatter plot\n",
    "axes[0, 0].scatter(y_test, best_predictions, alpha=0.6, color='purple')\n",
    "axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], \n",
    "                'r--', lw=2, label='Perfect Prediction')\n",
    "axes[0, 0].set_xlabel('Actual Position', fontsize=12)\n",
    "axes[0, 0].set_ylabel('Predicted Position', fontsize=12)\n",
    "axes[0, 0].set_title(f'Actual vs Predicted Positions\\n({best_model_name})', \n",
    "                     fontsize=14, fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Prediction error distribution\n",
    "errors = y_test - best_predictions\n",
    "axes[0, 1].hist(errors, bins=30, edgecolor='black', color='skyblue', alpha=0.7)\n",
    "axes[0, 1].axvline(x=0, color='red', linestyle='--', linewidth=2, label='Zero Error')\n",
    "axes[0, 1].set_xlabel('Prediction Error (positions)', fontsize=12)\n",
    "axes[0, 1].set_ylabel('Frequency', fontsize=12)\n",
    "axes[0, 1].set_title('Distribution of Prediction Errors', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Error by actual position\n",
    "error_df = pd.DataFrame({'Actual': y_test, 'Error': np.abs(errors)})\n",
    "error_by_position = error_df.groupby('Actual')['Error'].mean()\n",
    "axes[1, 0].bar(error_by_position.index, error_by_position.values, color='orange', alpha=0.7)\n",
    "axes[1, 0].set_xlabel('Actual Race Position', fontsize=12)\n",
    "axes[1, 0].set_ylabel('Mean Absolute Error', fontsize=12)\n",
    "axes[1, 0].set_title('Prediction Accuracy by Position', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Model comparison\n",
    "model_comparison = pd.DataFrame({\n",
    "    'Model': ['Random Forest', 'XGBoost'],\n",
    "    'MAE': [rf_mae, xgb_mae]\n",
    "})\n",
    "axes[1, 1].bar(model_comparison['Model'], model_comparison['MAE'], \n",
    "               color=['steelblue', 'coral'], alpha=0.7)\n",
    "axes[1, 1].set_ylabel('Mean Absolute Error (positions)', fontsize=12)\n",
    "axes[1, 1].set_title('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Add value labels on bars\n",
    "for i, v in enumerate(model_comparison['MAE']):\n",
    "    axes[1, 1].text(i, v + 0.05, f'{v:.2f}', ha='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./data/model_evaluation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n{best_model_name} Performance Summary:\")\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(y_test, best_predictions):.2f} positions\")\n",
    "print(f\"Standard Deviation of Errors: {np.std(errors):.2f}\")\n",
    "print(f\"Median Absolute Error: {np.median(np.abs(errors)):.2f}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save_model_md",
   "metadata": {},
   "source": [
    "## Step 10: Save the Model\n",
    "\n",
    "Let's save our trained model so we can use it later without retraining!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "save_model",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import joblib\n",
    "\n",
    "# Save the best model\n",
    "best_model = xgb_model if xgb_mae < rf_mae else rf_model\n",
    "\n",
    "# Save model and encoders\n",
    "joblib.dump(best_model, './models/f1_position_predictor.pkl')\n",
    "joblib.dump(le_driver, './models/driver_encoder.pkl')\n",
    "joblib.dump(le_team, './models/team_encoder.pkl')\n",
    "joblib.dump(le_circuit, './models/circuit_encoder.pkl')\n",
    "\n",
    "# Save feature names\n",
    "with open('./models/feature_names.txt', 'w') as f:\n",
    "    f.write(','.join(feature_columns))\n",
    "\n",
    "print(\"Model and encoders saved successfully!\")\n",
    "print(f\"\\nSaved files:\")\n",
    "print(\"  - ./models/f1_position_predictor.pkl\")\n",
    "print(\"  - ./models/driver_encoder.pkl\")\n",
    "print(\"  - ./models/team_encoder.pkl\")\n",
    "print(\"  - ./models/circuit_encoder.pkl\")\n",
    "print(\"  - ./models/feature_names.txt\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prediction_md",
   "metadata": {},
   "source": [
    "## Step 11: Make Predictions for a New Race\n",
    "\n",
    "Now let's use our model to predict race results! We'll create a function that takes qualifying results and predicts the race outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prediction_function",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "def predict_race_result(quali_results_dict):\n",
    "    \"\"\"\n",
    "    Predict race results based on qualifying positions and historical data.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    quali_results_dict : dict\n",
    "        Dictionary with keys: 'driver', 'team', 'quali_position', 'circuit'\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Predicted race results\n",
    "    \"\"\"\n",
    "    predictions = []\n",
    "    \n",
    "    for driver_data in quali_results_dict:\n",
    "        driver = driver_data['driver']\n",
    "        team = driver_data['team']\n",
    "        quali_pos = driver_data['quali_position']\n",
    "        circuit = driver_data['circuit']\n",
    "        \n",
    "        # Get historical stats\n",
    "        driver_stats = df_clean[df_clean['Abbreviation'] == driver]\n",
    "        team_stats = df_clean[df_clean['TeamName'] == team]\n",
    "        \n",
    "        if len(driver_stats) == 0 or len(team_stats) == 0:\n",
    "            print(f\"Warning: No historical data for {driver} or {team}\")\n",
    "            continue\n",
    "        \n",
    "        # Create feature vector\n",
    "        features = {\n",
    "            'QualiPosition': quali_pos,\n",
    "            'DriverAvgPosition': driver_stats['DriverAvgPosition'].iloc[-1],\n",
    "            'TeamAvgPosition': team_stats['TeamAvgPosition'].iloc[-1],\n",
    "            'DriverRaceCount': driver_stats['DriverRaceCount'].iloc[-1] + 1,\n",
    "            'RecentForm': driver_stats['RecentForm'].iloc[-1],\n",
    "            'GridPenalty': 0,  # Assume no penalty\n",
    "            'Driver_Encoded': le_driver.transform([driver])[0],\n",
    "            'Team_Encoded': le_team.transform([team])[0],\n",
    "            'Circuit_Encoded': le_circuit.transform([circuit])[0]\n",
    "        }\n",
    "        \n",
    "        # Make prediction\n",
    "        X_pred = pd.DataFrame([features])[feature_columns]\n",
    "        predicted_position = best_model.predict(X_pred)[0]\n",
    "        \n",
    "        predictions.append({\n",
    "            'Driver': driver,\n",
    "            'Team': team,\n",
    "            'Qualifying Position': quali_pos,\n",
    "            'Predicted Race Position': round(predicted_position, 1)\n",
    "        })\n",
    "    \n",
    "    results_df = pd.DataFrame(predictions)\n",
    "    results_df = results_df.sort_values('Predicted Race Position').reset_index(drop=True)\n",
    "    results_df.index = results_df.index + 1  # Start from 1\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Example: Predict a hypothetical race\n",
    "print(\"\\nExample Prediction: Hypothetical Race\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Sample qualifying results (you can modify these)\n",
    "example_quali = [\n",
    "    {'driver': 'VER', 'team': 'Red Bull Racing', 'quali_position': 1, 'circuit': 'Bahrain Grand Prix'},\n",
    "    {'driver': 'PER', 'team': 'Red Bull Racing', 'quali_position': 2, 'circuit': 'Bahrain Grand Prix'},\n",
    "    {'driver': 'LEC', 'team': 'Ferrari', 'quali_position': 3, 'circuit': 'Bahrain Grand Prix'},\n",
    "    {'driver': 'SAI', 'team': 'Ferrari', 'quali_position': 4, 'circuit': 'Bahrain Grand Prix'},\n",
    "    {'driver': 'HAM', 'team': 'Mercedes', 'quali_position': 5, 'circuit': 'Bahrain Grand Prix'},\n",
    "]\n",
    "\n",
    "predicted_results = predict_race_result(example_quali)\n",
    "print(predicted_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusion_md",
   "metadata": {},
   "source": [
    "## Conclusion and Next Steps\n",
    "\n",
    "Congratulations! You've built a complete F1 race prediction model! Here's what you learned:\n",
    "\n",
    "### What We Covered:\n",
    "1. **Data Collection**: Using APIs (FastF1) to get real F1 data\n",
    "2. **Data Exploration**: Understanding patterns through visualizations\n",
    "3. **Feature Engineering**: Creating meaningful variables from raw data\n",
    "4. **Model Training**: Using Random Forest and XGBoost algorithms\n",
    "5. **Model Evaluation**: Measuring performance with MAE\n",
    "6. **Making Predictions**: Using the model for new races\n",
    "\n",
    "### Model Performance:\n",
    "- Our model predicts race positions with an average error of ~2-3 positions\n",
    "- It correctly identifies strong patterns like quali position importance\n",
    "- Top teams and drivers are usually predicted accurately\n",
    "\n",
    "### Ways to Improve:\n",
    "1. **More Data**: Include more seasons (2018-2023)\n",
    "2. **Weather Data**: Add weather conditions as features\n",
    "3. **Tire Strategy**: Include pit stop and tire compound data\n",
    "4. **Circuit Characteristics**: Add track-specific features (length, corners, etc.)\n",
    "5. **Driver Head-to-Head**: Add historical performance against specific drivers\n",
    "6. **Deep Learning**: Try neural networks for even better predictions\n",
    "\n",
    "### Practice Exercises:\n",
    "1. Try predicting results for the 2024 season\n",
    "2. Add new features and see if accuracy improves\n",
    "3. Create a classification model for podium predictions (top 3)\n",
    "4. Visualize prediction accuracy for specific drivers/teams\n",
    "\n",
    "Keep experimenting and learning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}